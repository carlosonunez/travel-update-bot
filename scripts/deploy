#!/usr/bin/env bash
source $(dirname "$0")/helpers/shared_secrets.sh
source $(dirname "$0")/helpers/logging.sh
if test -f "$(dirname "$0")/../.env"
then
  export $(grep -Ev '^#' "$(dirname "$0")/../.env" | xargs -0)
fi
export AWS_SESSION_NAME="${TF_VAR_app_name}-session-$(date +%s)"
AWS_ACCESS_KEY_ID="${AWS_ACCESS_KEY_ID?Please define AWS_ACCESS_KEY_ID}"
AWS_SECRET_ACCESS_KEY="${AWS_SECRET_ACCESS_KEY?Please define AWS_SECRET_ACCESS_KEY}"
AWS_REGION="${AWS_REGION?Please define AWS_REGION}"
AWS_ROLE_ARN="${AWS_ROLE_ARN?Please define AWS_ROLE_ARN}"
AWS_STS_EXTERNAL_ID="${AWS_STS_EXTERNAL_ID?Please define AWS_STS_EXTERNAL_ID}"
ENVIRONMENT="${ENVIRONMENT:-test}"
DEPLOY_FUNCTIONS_ONLY="${DEPLOY_FUNCTIONS_ONLY:-false}"
AWS_ECR_ENABLE="${AWS_ECR_ENABLE:-false}"
AWS_ECR_REPUSH="${AWS_ECR_REPUSH:-false}"
AWS_CREDS_TEMP_FP="$(mktemp $PWD/aws-session-credentials-"$(date +%s)"-XXXXX)"
set -e

usage() {
  cat <<-USAGE
$(basename $0)
Deploys our functions onto serverless infrastructure.

ARGUMENTS

  -h, --help                    Prints this help screen.

ENVIRONMENT VARIABLES

  ENVIRONMENT=test              The environment being deployed into.

  DEPLOY_FUNCTIONS_ONLY=false   Disable re-deploying infrastructure and skip
                                straight to deploying functions.

  AWS_ECR_ENABLE                Enable building dual-architecture Docker images
                                into AWS ECR.

  AWS_ECR_REPUSH                Re-push Docker images into AWS ECR.
                                No effect if AWS_ECR_ENABLE=false.

NOTES

  - If setting AWS_ECR_ENABLE=true, also make sure that your "provider" block
    inside of "serverless.yml" looks like this:

    provider:
      name: aws
      runtime: # Your runtime
      ...
      ecr:
        images:
          app:
            uri: \${file(./secrets/ecr_repository)}:app-\${self:custom.architecture}

    And that you have a "custom" block that looks like this:

    custom:
      architecture: arm64 # or amd64

USAGE
}


write_lambda_secrets() {
  stage="develop"
  if test "$ENVIRONMENT" == "production" ||
    test "$ENVIRONMENT" == "prod"
  then stage="v1"
  fi
  info "Getting integration test API Gateway endpoint."
  endpoint_url=$(docker-compose -f docker-compose.deploy.yml run \
      --rm serverless info --stage "$stage" | \
    grep -E 'http.*\/ping' | \
    sed 's/.*\(http.*\)\/ping/\1/' | \
    tr -d $'\r' | \
    tr -d $'\n')

  info "Getting API Gateway default API key."
  api_key=$(docker-compose -f docker-compose.deploy.yml \
      run --rm serverless info --stage "$stage" | \
    grep -E 'default_key_test:' | \
    sed 's/.*default_key_test: //' | \
    tr -d $'\r' | \
    tr -d $'\n'
  )
  if test -z "$endpoint_url"
  then
    error "We couldn't find a deployed endpoint."
    exit 1
  fi
  if test -z "$api_key"
  then
    error "We couldn't find an API key."
    exit 1
  fi
  write_secret "$endpoint_url" "endpoint_name"
  write_secret "$api_key" "api_key"
}

write_infrastructure_secrets() {
  info "Getting infrastructure secrets."
  tf_output=$(2>&1 docker-compose -f docker-compose.deploy.yml run \
    -e ENVIRONMENT="$ENVIRONMENT" \
    --rm \
    terraform output | tr -d $'\r')
  info "Output: $tf_output"
  for output_var in app_account_ak app_account_sk certificate_arn ecr_repository \
    ecr_repository_password
  do
    secret_value=$(grep -E "^$output_var = " <<< "$tf_output" | \
      sed "s/^$output_var = //")
    if test -z "$secret_value"
    then
      error "===> ${output_var}: retrieval failed"
      exit 1
    fi
    info "===> ${output_var}: retrieved"
    write_secret "$secret_value" "$output_var"
  done
}

push_app_to_ecr() {
  grep -Eiq '^true$' <<< "$AWS_ECR_ENABLE"  || return 0

  repository="$(read_secret "ecr_repository")"
  docker login "$repository" --username AWS --password \
    "$(read_secret "ecr_repository_password")" || return 1

  for arch in amd64 arm64
  do
    image_name="$repository:app-$arch"
    if grep -Eiq '^true$' <<< "$AWS_ECR_REPUSH" ||
      test -z "$(docker images "$repository")"
    then
      docker build --platform="linux/$arch" --no-cache --pull \
        -t "$image_name" . && docker push "$image_name"
    fi
  done
}

deploy_serverless_infrastructure() {
  export $(get_aws_credentials)
  info "Deploying serverless infrastructure."
  docker-compose -f docker-compose.deploy.yml run --rm \
    -e TF_VAR_aws_ecr_enable="${AWS_ECR_ENABLE}" \
    deploy-serverless-infra-"$ENVIRONMENT" &&
  if test "$ENVIRONMENT" == "production"
  then
    docker-compose -f docker-compose.deploy.yml build deploy-serverless-domain-production &&
    docker-compose -f docker-compose.deploy.yml run --rm deploy-serverless-domain-production
  fi &&
  write_infrastructure_secrets
}

deploy_serverless_functions() {
  info "Deploying serverless functions."
  export $(get_aws_credentials)
  docker-compose -f docker-compose.deploy.yml build deploy-serverless-functions-"$ENVIRONMENT" &&
  docker-compose -f docker-compose.deploy.yml run --rm deploy-serverless-functions-"$ENVIRONMENT" &&
    write_lambda_secrets
}

remove_secret_folder_if_present() {
  test -d "$(dirname "$0")/../secrets" && rm -rf "$(dirname "$0")/../secrets" || true
}

generate_aws_credentials() {
  info "Retrieving an AWS session token"
  printf "AWS_ACCESS_KEY_ID=%s AWS_SECRET_ACCESS_KEY=%s AWS_SESSION_TOKEN=%s" \
    $(docker-compose -f docker-compose.deploy.yml run -T --rm obtain-aws-session-credentials) \
    >> "$AWS_CREDS_TEMP_FP"
}

remove_aws_credentials() {
  info "Removing AWS credentials"
  rm -f "$AWS_CREDS_TEMP_FP"
}

get_aws_credentials() {
  cat "$AWS_CREDS_TEMP_FP"
}

if [ "$1" == "-h" ] || [ "$1" == "--help" ]
then
  usage
  exit 0
fi

trap 'remove_aws_credentials' INT EXIT

if [ "$DEPLOY_FUNCTIONS_ONLY" == "true" ]
then
  warn "Only deploying functions, as requested."
  deploy_serverless_functions
else
  remove_secret_folder_if_present &&
    generate_aws_credentials &&
    deploy_serverless_infrastructure &&
    push_app_to_ecr &&
    deploy_serverless_functions
fi
